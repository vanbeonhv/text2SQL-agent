# LLM Provider Configuration
LLM_PROVIDER=gemini  # Options: gemini, openai, claude
GEMINI_API_KEY=your_gemini_api_key_here
# OPENAI_API_KEY=your_openai_api_key_here  # Uncomment when using OpenAI
# ANTHROPIC_API_KEY=your_claude_api_key_here  # Uncomment when using Claude

# LLM Model Tiers
THINKING_MODEL=gemini-1.5-pro        # For SQL generation, error correction (slower, more accurate)
LIGHTWEIGHT_MODEL=gemini-1.5-flash   # For summaries, insights (faster, cheaper)

# Database Paths
TARGET_DB_PATH=data/target.db
HISTORY_DB_PATH=data/history.db
SCHEMA_PATH=data/schema.json

# Agent Configuration
MAX_RETRY_ATTEMPTS=3
QUERY_TIMEOUT_SECONDS=30
MAX_ROWS_RETURN=1000
MAX_CONVERSATION_MESSAGES=10  # Limit conversation history for context

# Response Formatting
ENABLE_LLM_INSIGHTS=true             # Toggle LLM insights for aggregations
FORMAT_WITH_LLM_THRESHOLD=100        # Rows > threshold always use Python formatting
MAX_DISPLAY_ROWS=50                  # Maximum rows to display in markdown table

# Logging
LOG_LEVEL=INFO
